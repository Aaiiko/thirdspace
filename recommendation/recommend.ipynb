{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, Linear\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.linear = Linear(hidden_channels, num_features)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.leaky_relu(self.conv1(x, edge_index))\n",
    "        x = F.leaky_relu(self.conv2(x, edge_index))\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(user_likes, all_restaurants, min_stars):\n",
    "    all_data = pd.concat([user_likes, all_restaurants], ignore_index=True)\n",
    "    all_data['star_diff'] = all_data['Star'] - min_stars\n",
    "    all_data.drop_duplicates()\n",
    "    all_data.reset_index()\n",
    "    price_dict = {'$': 1, '$$': 2, '$$$': 3, '$$$$': 4, 'n/a': 2}\n",
    "    \n",
    "    all_data['Price'] = all_data['Price'].map(price_dict)\n",
    "    all_data['Price'].fillna(2, inplace=True)\n",
    "    all_data['Star'].fillna(3.5, inplace=True)\n",
    "    all_data = all_data.dropna(subset=['Area'])\n",
    "\n",
    "    \n",
    "    le_area = LabelEncoder()\n",
    "    all_data['Area_encoded'] = le_area.fit_transform(all_data['Area'])\n",
    "    \n",
    "    category_vectorizer = CountVectorizer(tokenizer=lambda x: x.split(','), lowercase=False, token_pattern=None)\n",
    "    category_encoded = category_vectorizer.fit_transform(all_data['Category'])\n",
    "    category_df = pd.DataFrame(category_encoded.toarray(), columns=category_vectorizer.get_feature_names_out())\n",
    "    category_df.fillna(0, inplace=True)\n",
    "\n",
    "    service_vectorizer = CountVectorizer(tokenizer=lambda x: x.split(','), lowercase=False, token_pattern=None)\n",
    "    service_encoded = service_vectorizer.fit_transform(all_data['Services'])\n",
    "    service_df = pd.DataFrame(service_encoded.toarray(), columns=service_vectorizer.get_feature_names_out())\n",
    "    service_df.fillna(0, inplace=True)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    all_data[['Star_normalized', 'Price_normalized', 'star_diff_normalized']] = scaler.fit_transform(all_data[['Star', 'Price', 'star_diff']])\n",
    "    \n",
    "    all_data['Price_normalized'].fillna(0, inplace=True)\n",
    "    all_data['Star_normalized'].fillna(0, inplace=True)\n",
    "    all_data['star_diff_normalized'].fillna(0, inplace=True)\n",
    "\n",
    "    feature_df = pd.concat([\n",
    "        all_data[['Star_normalized', 'Price_normalized', 'star_diff_normalized', 'Area_encoded']].reset_index(drop=True),\n",
    "        category_df.reset_index(drop=True),\n",
    "        service_df.reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "    \n",
    "    features = feature_df.values\n",
    "    \n",
    "\n",
    "    return torch.FloatTensor(features), all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(features, user_likes, user_dislikes):\n",
    "    num_user_likes = len(user_likes)\n",
    "    num_user_dislikes = len(user_dislikes)\n",
    "    num_total = len(features)\n",
    "\n",
    "    edge_index = []\n",
    "    edge_types = [] \n",
    "\n",
    " \n",
    "    for i in range(num_user_likes):\n",
    "        for j in range(num_user_likes, num_total):\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])\n",
    "            edge_types.append(1)\n",
    "\n",
    "   \n",
    "    for i in range(num_user_dislikes):\n",
    "        for j in range(num_user_dislikes, num_total):\n",
    "            edge_index.append([i + num_user_likes, j]) \n",
    "            edge_index.append([j, i + num_user_likes]) \n",
    "            edge_types.append(-1) \n",
    "\n",
    "    edge_index = torch.LongTensor(edge_index).t().contiguous()\n",
    "    edge_types = torch.tensor(edge_types, dtype=torch.float).view(-1, 1) \n",
    "\n",
    "    return Data(x=features, edge_index=edge_index, edge_attr=edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, graph_data, num_epochs=100):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(graph_data.x, graph_data.edge_index)\n",
    "        loss = criterion(out, graph_data.x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(model, graph_data, user_likes, all_restaurants, top_k=50):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        node_embeddings = model(graph_data.x, graph_data.edge_index)\n",
    "\n",
    "    user_embeddings = node_embeddings[:len(user_likes)]\n",
    "    restaurant_embeddings = node_embeddings[len(user_likes):]\n",
    "\n",
    "    noise = torch.normal(mean=0.0, std=0.3, size=user_embeddings.size())\n",
    "    noisy_user = user_embeddings+noise\n",
    "    \n",
    "    similarities = torch.mm(noisy_user.mean(dim=0).unsqueeze(0), restaurant_embeddings.t())\n",
    "    _, indices = similarities.topk(top_k)\n",
    "\n",
    "    \n",
    "    final_indices = []\n",
    "    seen_restaurants = set(user_likes['Name'])\n",
    "    \n",
    "    for idx in indices.squeeze():\n",
    "        restaurant_name = all_restaurants.iloc[idx.item()]['Name']\n",
    "        if restaurant_name not in seen_restaurants:\n",
    "            final_indices.append(idx.item())\n",
    "            if len(final_indices) == top_k:\n",
    "                break\n",
    "    \n",
    "    return all_restaurants.iloc[indices.squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 2.8852\n"
     ]
    }
   ],
   "source": [
    "min_stars = 3.0\n",
    "data_file = 'Restaurants_Seattle.csv'\n",
    "user_data_file = 'Sample_User.xlsx'\n",
    "dislikes = 'User_dislikes.xlsx'\n",
    "\n",
    "user_likes = pd.read_excel(user_data_file)\n",
    "user_dislikes = pd.read_excel(dislikes)\n",
    "data = pd.read_csv(data_file)\n",
    "\n",
    "features, processed_data = preprocess_data(user_data, data, min_stars)\n",
    "graph_data = create_graph(features, user_likes, user_dislikes)\n",
    "\n",
    "model = GNN(num_features=features.shape[1], hidden_channels=64)\n",
    "train_model(model, graph_data)\n",
    "\n",
    "print(len(processed_data))\n",
    "recommendations = get_recommendations(model, graph_data, user_likes, processed_data, top_k=50)\n",
    "display(recommendations[['Name', 'Star', 'Stars_count', 'Price', 'Area', 'Category', 'Services', 'Searched City']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add method to generate multiple restaurants quickly on same model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
