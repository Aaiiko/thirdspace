{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, Linear\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.linear = Linear(hidden_channels, num_features)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.leaky_relu(self.conv1(x, edge_index))\n",
    "        x = F.leaky_relu(self.conv2(x, edge_index))\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(user_likes_df, all_restaurants_df, preferred_min_stars):\n",
    "    all_data = pd.concat([user_likes_df, all_restaurants_df], ignore_index=True)\n",
    "    all_data['star_diff'] = all_data['Star'] - preferred_min_stars\n",
    "    all_data.drop_duplicates()\n",
    "    price_dict = {'$': 1, '$$': 2, '$$$': 3, '$$$$': 4, 'n/a': 0}\n",
    "    all_data['Price'] = all_data['Price'].map(price_dict)\n",
    "    \n",
    "    le_area = LabelEncoder()\n",
    "    all_data['Area_encoded'] = le_area.fit_transform(all_data['Area'])\n",
    "    \n",
    "    category_vectorizer = CountVectorizer(tokenizer=lambda x: x.split(','), lowercase=False, token_pattern=None)\n",
    "    category_encoded = category_vectorizer.fit_transform(all_data['Category'])\n",
    "    category_df = pd.DataFrame(category_encoded.toarray(), columns=category_vectorizer.get_feature_names_out())\n",
    "    \n",
    "    service_vectorizer = CountVectorizer(tokenizer=lambda x: x.split(','), lowercase=False, token_pattern=None)\n",
    "    service_encoded = service_vectorizer.fit_transform(all_data['Services'])\n",
    "    service_df = pd.DataFrame(service_encoded.toarray(), columns=service_vectorizer.get_feature_names_out())\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    all_data[['Star_normalized', 'Price_normalized', 'star_diff_normalized']] = scaler.fit_transform(all_data[['Star', 'Price', 'star_diff']])\n",
    "    \n",
    "    feature_df = pd.concat([\n",
    "        all_data[['Star_normalized', 'Price_normalized', 'star_diff_normalized', 'Area_encoded']],\n",
    "        category_df,\n",
    "        service_df\n",
    "    ], axis=1)\n",
    "    \n",
    "    features = feature_df.values\n",
    "    \n",
    "    return torch.FloatTensor(features), all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(features, user_likes_df, all_restaurants_df):\n",
    "    num_user_likes = len(user_likes_df)\n",
    "    num_total = len(features)\n",
    "    \n",
    "    edge_index = []\n",
    "    for i in range(num_user_likes):\n",
    "        for j in range(num_user_likes, num_total):\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])\n",
    "    \n",
    "    edge_index = torch.LongTensor(edge_index).t().contiguous()\n",
    "    \n",
    "    return Data(x=features, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, graph_data, num_epochs=100):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(graph_data.x, graph_data.edge_index)\n",
    "        loss = criterion(out, graph_data.x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(model, graph_data, user_likes_df, all_restaurants_df, top_k=100):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        node_embeddings = model(graph_data.x, graph_data.edge_index)\n",
    "    \n",
    "    user_embeddings = node_embeddings[:len(user_likes_df)]\n",
    "    restaurant_embeddings = node_embeddings[len(user_likes_df):]\n",
    "    \n",
    "    similarities = torch.mm(user_embeddings.mean(dim=0).unsqueeze(0), restaurant_embeddings.t())\n",
    "    \n",
    "    #_, indices = similarities.topk(min(len(all_restaurants_df), similarities.size(1)))\n",
    "    _, indices = similarities.topk(top_k)\n",
    "    print(len(indices))\n",
    "    \n",
    "    final_indices = []\n",
    "    seen_restaurants = set(user_likes_df['Name'])\n",
    "    \n",
    "    for idx in indices.squeeze():\n",
    "        restaurant_name = all_restaurants_df.iloc[idx.item()]['Name']\n",
    "        if restaurant_name not in seen_restaurants:\n",
    "            final_indices.append(idx.item())\n",
    "            if len(final_indices) == top_k:\n",
    "                break\n",
    "    \n",
    "    return all_restaurants_df.iloc[final_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: nan\n",
      "Epoch 20/100, Loss: nan\n",
      "Epoch 30/100, Loss: nan\n",
      "Epoch 40/100, Loss: nan\n",
      "Epoch 50/100, Loss: nan\n",
      "Epoch 60/100, Loss: nan\n",
      "Epoch 70/100, Loss: nan\n",
      "Epoch 80/100, Loss: nan\n",
      "Epoch 90/100, Loss: nan\n",
      "Epoch 100/100, Loss: nan\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Star</th>\n",
       "      <th>Stars_count</th>\n",
       "      <th>Price</th>\n",
       "      <th>Area</th>\n",
       "      <th>Category</th>\n",
       "      <th>Services</th>\n",
       "      <th>Searched City</th>\n",
       "      <th>star_diff</th>\n",
       "      <th>Area_encoded</th>\n",
       "      <th>Star_normalized</th>\n",
       "      <th>Price_normalized</th>\n",
       "      <th>star_diff_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Star, Stars_count, Price, Area, Category, Services, Searched City, star_diff, Area_encoded, Star_normalized, Price_normalized, star_diff_normalized]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preferred_min_stars = 4.0\n",
    "data_file = 'Restaurants_Seattle.csv'\n",
    "user_data_file = 'Sample_User.xlsx'\n",
    "\n",
    "user_data = pd.read_excel(user_data_file)\n",
    "data = pd.read_csv(data_file)\n",
    "\n",
    "features, processed_data = preprocess_data(user_data, data, preferred_min_stars)\n",
    "graph_data = create_graph(features, user_data, processed_data)\n",
    "\n",
    "model = GNN(num_features=features.shape[1], hidden_channels=64)\n",
    "train_model(model, graph_data)\n",
    "\n",
    "recommendations = get_recommendations(model, graph_data, user_data, processed_data, top_k=5)\n",
    "display(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add method to generate multiple restaurants quickly on same model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
